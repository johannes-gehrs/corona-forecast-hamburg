{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unauthorized-convenience",
   "metadata": {},
   "source": [
    "### This is a toy project. Do not take it serious.\n",
    "\n",
    "Load the weather from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forty-batch",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "weather_df = pd.read_csv(\"./data/tageswerte_KL_01975_akt/produkt_klima_tag_20190907_20210309_01975.txt\", \n",
    "                             delimiter=\";\", skipinitialspace=True, usecols=['TMK', 'RSK', 'SHK_TAG', 'SDK', 'MESS_DATUM', 'UPM'],\n",
    "                        parse_dates=['MESS_DATUM'])\n",
    "weather_df.rename(columns={'MESS_DATUM': 'date', 'RSK': 'precipitation', 'SDK': 'sun', 'SHK_TAG': 'snow', 'TMK': 'temperature', 'UPM': 'humidity'}, inplace=True)\n",
    "weather_df.set_index('date',  inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-costume",
   "metadata": {},
   "source": [
    "Load the incidence data from Excel\n",
    "\n",
    "One row is messed up, I needed to fix the date there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "political-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 100)\n",
    "\n",
    "incidence_df = pd.read_excel(\"./data/d-inzidenz-zum-download-service.xlsx\", usecols=['Unnamed: 1', 'Unnamed: 2'])\n",
    "incidence_df.drop([0], inplace=True)\n",
    "incidence_df.rename(columns={'Unnamed: 1': 'date', 'Unnamed: 2': 'cumulative_incidence'}, inplace=True)\n",
    "\n",
    "incidence_df.loc[[316], 'date'] = '2021-01-21 00:00:00'  # messed up date in row 316\n",
    "incidence_df['date'] = pd.to_datetime(incidence_df['date'])\n",
    "incidence_df.set_index('date',  inplace=True)\n",
    "\n",
    "incidence_df['daily_incidence'] = incidence_df['cumulative_incidence'].diff()\n",
    "incidence_df.drop(['cumulative_incidence'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-finland",
   "metadata": {},
   "source": [
    "Load the Google mobility data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compact-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sub_region_1', 'date', 'retail_and_recreation_percent_change_from_baseline', \n",
    "        'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "        'parks_percent_change_from_baseline',\n",
    "        'transit_stations_percent_change_from_baseline',\n",
    "        'workplaces_percent_change_from_baseline',\n",
    "        'residential_percent_change_from_baseline']\n",
    "\n",
    "mobility_df = pd.read_csv(\"./data/2020_DE_Region_Mobility_Report.csv\", usecols=cols, parse_dates=['date'])\n",
    "mobility_df = mobility_df.loc[mobility_df['sub_region_1'] == \"Hamburg\"]\n",
    "mobility_df.reset_index(drop=True, inplace=True)\n",
    "mobility_df.set_index('date',  inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-bahamas",
   "metadata": {},
   "source": [
    "Join all the data frames to one big data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weather_df.join(incidence_df).join(mobility_df)\n",
    "df.dropna(subset=['sub_region_1', 'daily_incidence'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-officer",
   "metadata": {},
   "source": [
    "I think values where this seems appropriate should be scaled to a value between 0 and 1\n",
    "\n",
    "I'm replacing the weather and mobility stuff but keep the original incidence cause this may be interesting to look at later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hungarian-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as prep\n",
    "\n",
    "scaler = prep.MinMaxScaler()\n",
    "\n",
    "scale_and_replace_cols = ['precipitation', 'temperature', 'humidity', 'sun', 'snow',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline',\n",
    "                          'transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline',\n",
    "                          'residential_percent_change_from_baseline']\n",
    "df[scale_and_replace_cols] = scaler.fit_transform(df[scale_and_replace_cols])\n",
    "\n",
    "df[['daily_incidence_scaled']] = scaler.fit_transform(df[['daily_incidence']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-pacific",
   "metadata": {},
   "source": [
    "I think the best way to model this might be to take the incidence 7 days later as a target variable and then basically provide this to the model for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sound-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_incidence_scaled_target'] = df['daily_incidence_scaled'].shift(periods=-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-black",
   "metadata": {},
   "source": [
    "Let's get a feel for the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-objective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precipitation                                         0.018136\n",
       "sun                                                  -0.555762\n",
       "snow                                                  0.054519\n",
       "temperature                                          -0.536186\n",
       "humidity                                              0.578397\n",
       "retail_and_recreation_percent_change_from_baseline   -0.269039\n",
       "grocery_and_pharmacy_percent_change_from_baseline     0.011903\n",
       "parks_percent_change_from_baseline                   -0.589284\n",
       "transit_stations_percent_change_from_baseline        -0.293226\n",
       "workplaces_percent_change_from_baseline              -0.138331\n",
       "residential_percent_change_from_baseline              0.334857\n",
       "daily_incidence_scaled                                0.890412\n",
       "daily_incidence_scaled_target                         1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['daily_incidence_scaled_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-logistics",
   "metadata": {},
   "source": [
    "Let's split up the dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affecting-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# not quit sure why the mobility data are sometimes NaN but I need to drop them to make the models work\n",
    "df_only_complete = df.dropna(subset=['daily_incidence_scaled_target', 'parks_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline'])\n",
    "\n",
    "predictive_cols = scale_and_replace_cols + ['daily_incidence_scaled']\n",
    "\n",
    "X = df_only_complete[predictive_cols]\n",
    "Y = df_only_complete['daily_incidence_scaled_target'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20, random_state=204408712) # using a randomly chosen but fixed random initializer to make things repoducable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-recycling",
   "metadata": {},
   "source": [
    "\n",
    "Now we can benchmark various regression models (inspired by https://www.kaggle.com/junkal/selecting-the-best-regression-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "short-investigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -0.009278 (0.003699)\n",
      "ScaledLASSO: -0.052608 (0.010115)\n",
      "ScaledEN: -0.052608 (0.010115)\n",
      "ScaledKNN: -0.012944 (0.003831)\n",
      "ScaledCART: -0.014918 (0.006699)\n",
      "ScaledGBM: -0.010332 (0.004238)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-enforcement",
   "metadata": {},
   "source": [
    "Looks like linear regression works well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raised-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidence on 2021-03-07 00:00:00: 155\n",
      "Incidence on 2021-03-08 00:00:00: 265\n",
      "Incidence on 2021-03-09 00:00:00: 195\n",
      "Incidence on 2021-03-10 00:00:00: 237\n",
      "Incidence on 2021-03-11 00:00:00: 281\n",
      "Incidence on 2021-03-12 00:00:00: 213\n",
      "Incidence on 2021-03-13 00:00:00: 234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "      <th>sun</th>\n",
       "      <th>snow</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>daily_incidence</th>\n",
       "      <th>sub_region_1</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "      <th>daily_incidence_scaled</th>\n",
       "      <th>daily_incidence_scaled_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344311</td>\n",
       "      <td>0.717583</td>\n",
       "      <td>183</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.365922</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.265714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386228</td>\n",
       "      <td>0.770792</td>\n",
       "      <td>234</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.310056</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.338571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323353</td>\n",
       "      <td>0.730681</td>\n",
       "      <td>268</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.142458</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.387143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254491</td>\n",
       "      <td>0.547151</td>\n",
       "      <td>223</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.318436</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.322857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.749018</td>\n",
       "      <td>232</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.335714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precipitation       sun  snow  temperature  humidity  \\\n",
       "date                                                               \n",
       "2021-03-02            0.0  0.472506   0.0     0.344311  0.717583   \n",
       "2021-03-03            0.0  0.427031   0.0     0.386228  0.770792   \n",
       "2021-03-04            0.0  0.000000   0.0     0.323353  0.730681   \n",
       "2021-03-05            0.0  0.660684   0.0     0.254491  0.547151   \n",
       "2021-03-06            0.0  0.069766   0.0     0.314371  0.749018   \n",
       "\n",
       "           daily_incidence sub_region_1  \\\n",
       "date                                      \n",
       "2021-03-02             183      Hamburg   \n",
       "2021-03-03             234      Hamburg   \n",
       "2021-03-04             268      Hamburg   \n",
       "2021-03-05             223      Hamburg   \n",
       "2021-03-06             232      Hamburg   \n",
       "\n",
       "            retail_and_recreation_percent_change_from_baseline  \\\n",
       "date                                                             \n",
       "2021-03-02                                              -45.0    \n",
       "2021-03-03                                              -48.0    \n",
       "2021-03-04                                              -53.0    \n",
       "2021-03-05                                              -50.0    \n",
       "2021-03-06                                              -62.0    \n",
       "\n",
       "            grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "date                                                            \n",
       "2021-03-02                                           0.793388   \n",
       "2021-03-03                                           0.768595   \n",
       "2021-03-04                                           0.768595   \n",
       "2021-03-05                                           0.793388   \n",
       "2021-03-06                                           0.727273   \n",
       "\n",
       "            parks_percent_change_from_baseline  \\\n",
       "date                                             \n",
       "2021-03-02                            0.365922   \n",
       "2021-03-03                            0.310056   \n",
       "2021-03-04                            0.142458   \n",
       "2021-03-05                            0.318436   \n",
       "2021-03-06                            0.136872   \n",
       "\n",
       "            transit_stations_percent_change_from_baseline  \\\n",
       "date                                                        \n",
       "2021-03-02                                       0.485714   \n",
       "2021-03-03                                       0.471429   \n",
       "2021-03-04                                       0.400000   \n",
       "2021-03-05                                       0.457143   \n",
       "2021-03-06                                       0.371429   \n",
       "\n",
       "            workplaces_percent_change_from_baseline  \\\n",
       "date                                                  \n",
       "2021-03-02                                 0.471154   \n",
       "2021-03-03                                 0.471154   \n",
       "2021-03-04                                 0.451923   \n",
       "2021-03-05                                 0.480769   \n",
       "2021-03-06                                 0.701923   \n",
       "\n",
       "            residential_percent_change_from_baseline  daily_incidence_scaled  \\\n",
       "date                                                                           \n",
       "2021-03-02                                  0.485714                0.265714   \n",
       "2021-03-03                                  0.485714                0.338571   \n",
       "2021-03-04                                  0.542857                0.387143   \n",
       "2021-03-05                                  0.485714                0.322857   \n",
       "2021-03-06                                  0.342857                0.335714   \n",
       "\n",
       "            daily_incidence_scaled_target  \n",
       "date                                       \n",
       "2021-03-02                            NaN  \n",
       "2021-03-03                            NaN  \n",
       "2021-03-04                            NaN  \n",
       "2021-03-05                            NaN  \n",
       "2021-03-06                            NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/53553226/1430384\n",
    "def get_unscaled_incidence(value):\n",
    "    colname = 'daily_incidence_scaled'\n",
    "    exactmatch = df[df[colname] == value]\n",
    "    if not exactmatch.empty:\n",
    "        return exactmatch.index\n",
    "    else:\n",
    "        lowerneighbour_ind = df[df[colname] < value][colname].idxmax()\n",
    "        return df.loc[lowerneighbour_ind]['daily_incidence']\n",
    "\n",
    "# From https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "# df[predictive_cols].tail(5)\n",
    "for row, result in zip(df[predictive_cols].tail(7).index  + pd.DateOffset(days=7), regr.predict(df[predictive_cols].tail(7))):\n",
    "    print(f\"Incidence on {row}: {get_unscaled_incidence(result)}\")\n",
    "\n",
    "    \n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
