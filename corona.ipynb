{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "female-president",
   "metadata": {},
   "source": [
    "### This is a toy project. Do not take it serious.\n",
    "\n",
    "Load the weather from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automotive-block",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "weather_df = pd.read_csv(\"./data/klarchiv_01975_daily_akt/produkt_klima_tag_20190904_20210306_01975.txt\", \n",
    "                             delimiter=\";\", skipinitialspace=True, usecols=['TMK', 'RSK', 'SHK_TAG', 'SDK', 'MESS_DATUM', 'UPM'],\n",
    "                        parse_dates=['MESS_DATUM'])\n",
    "weather_df.rename(columns={'MESS_DATUM': 'date', 'RSK': 'precipitation', 'SDK': 'sun', 'SHK_TAG': 'snow', 'TMK': 'temperature', 'UPM': 'humidity'}, inplace=True)\n",
    "weather_df.set_index('date',  inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-maker",
   "metadata": {},
   "source": [
    "Load the incidence data from Excel\n",
    "\n",
    "One row is messed up, I needed to fix the date there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imperial-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 100)\n",
    "\n",
    "incidence_df = pd.read_excel(\"./data/d-inzidenz-zum-download-service.xlsx\", usecols=['Unnamed: 1', 'Unnamed: 2'])\n",
    "incidence_df.drop([0], inplace=True)\n",
    "incidence_df.rename(columns={'Unnamed: 1': 'date', 'Unnamed: 2': 'cumulative_incidence'}, inplace=True)\n",
    "\n",
    "incidence_df.loc[[316], 'date'] = '2021-01-21 00:00:00'  # messed up date in row 316\n",
    "incidence_df['date'] = pd.to_datetime(incidence_df['date'])\n",
    "incidence_df.set_index('date',  inplace=True)\n",
    "\n",
    "incidence_df['daily_incidence'] = incidence_df['cumulative_incidence'].diff()\n",
    "incidence_df.drop(['cumulative_incidence'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-parker",
   "metadata": {},
   "source": [
    "Load the Google mobility data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrow-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sub_region_1', 'date', 'retail_and_recreation_percent_change_from_baseline', \n",
    "        'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "        'parks_percent_change_from_baseline',\n",
    "        'transit_stations_percent_change_from_baseline',\n",
    "        'workplaces_percent_change_from_baseline',\n",
    "        'residential_percent_change_from_baseline']\n",
    "\n",
    "mobility_df = pd.read_csv(\"./data/2020_DE_Region_Mobility_Report.csv\", usecols=cols, parse_dates=['date'])\n",
    "mobility_df = mobility_df.loc[mobility_df['sub_region_1'] == \"Hamburg\"]\n",
    "mobility_df.reset_index(drop=True, inplace=True)\n",
    "mobility_df.set_index('date',  inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-soviet",
   "metadata": {},
   "source": [
    "Join all the data frames to one big data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upset-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weather_df.join(incidence_df).join(mobility_df)\n",
    "df.dropna(subset=['sub_region_1', 'daily_incidence'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-dining",
   "metadata": {},
   "source": [
    "I think values where this seems appropriate should be scaled to a value between 0 and 1\n",
    "\n",
    "I'm replacing the weather and mobility stuff but keep the original incidence cause this may be interesting to look at later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solved-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as prep\n",
    "\n",
    "scaler = prep.MinMaxScaler()\n",
    "\n",
    "scale_and_replace_cols = ['precipitation', 'temperature', 'humidity', 'sun', 'snow',\n",
    "                          'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "                          'parks_percent_change_from_baseline',\n",
    "                          'transit_stations_percent_change_from_baseline',\n",
    "                          'workplaces_percent_change_from_baseline',\n",
    "                          'residential_percent_change_from_baseline']\n",
    "df[scale_and_replace_cols] = scaler.fit_transform(df[scale_and_replace_cols])\n",
    "\n",
    "df[['daily_incidence_scaled']] = scaler.fit_transform(df[['daily_incidence']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-capitol",
   "metadata": {},
   "source": [
    "I think the best way to model this might be to take the incidence 7 days later as a target variable and then basically provide this to the model for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_incidence_scaled_target'] = df['daily_incidence_scaled'].shift(periods=-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-beaver",
   "metadata": {},
   "source": [
    "Let's get a feel for the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "irish-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precipitation                                         0.020916\n",
       "sun                                                  -0.558816\n",
       "snow                                                  0.056000\n",
       "temperature                                          -0.537001\n",
       "humidity                                              0.579527\n",
       "retail_and_recreation_percent_change_from_baseline   -0.265704\n",
       "grocery_and_pharmacy_percent_change_from_baseline     0.008979\n",
       "parks_percent_change_from_baseline                   -0.592633\n",
       "transit_stations_percent_change_from_baseline        -0.290842\n",
       "workplaces_percent_change_from_baseline              -0.137817\n",
       "residential_percent_change_from_baseline              0.332857\n",
       "daily_incidence_scaled                                0.890326\n",
       "daily_incidence_scaled_target                         1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['daily_incidence_scaled_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-methodology",
   "metadata": {},
   "source": [
    "Let's split up the dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prerequisite-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# not quit sure why the mobility data are sometimes NaN but I need to drop them to make the models work\n",
    "df_only_complete = df.dropna(subset=['daily_incidence_scaled_target', 'parks_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline'])\n",
    "\n",
    "predictive_cols = scale_and_replace_cols + ['daily_incidence_scaled']\n",
    "\n",
    "X = df_only_complete[predictive_cols]\n",
    "Y = df_only_complete['daily_incidence_scaled_target'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.20, random_state=204408712) # using a randomly chosen but fixed random initializer to make things repoducable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-approval",
   "metadata": {},
   "source": [
    "\n",
    "Now we can benchmark various regression models (inspired by https://www.kaggle.com/junkal/selecting-the-best-regression-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "about-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: -0.011071 (0.004385)\n",
      "ScaledLASSO: -0.057529 (0.012094)\n",
      "ScaledEN: -0.057529 (0.012094)\n",
      "ScaledKNN: -0.014302 (0.005175)\n",
      "ScaledCART: -0.021635 (0.008154)\n",
      "ScaledGBM: -0.011802 (0.004393)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-editor",
   "metadata": {},
   "source": [
    "Looks like linear regression works well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "loving-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidence on 2021-03-05 00:00:00: 188\n",
      "Incidence on 2021-03-06 00:00:00: 206\n",
      "Incidence on 2021-03-07 00:00:00: 147\n",
      "Incidence on 2021-03-08 00:00:00: 258\n",
      "Incidence on 2021-03-09 00:00:00: 195\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/53553226/1430384\n",
    "def get_unscaled_incidence(value):\n",
    "    colname = 'daily_incidence_scaled'\n",
    "    exactmatch = df[df[colname] == value]\n",
    "    if not exactmatch.empty:\n",
    "        return exactmatch.index\n",
    "    else:\n",
    "        lowerneighbour_ind = df[df[colname] < value][colname].idxmax()\n",
    "        return df.loc[lowerneighbour_ind]['daily_incidence']\n",
    "\n",
    "# From https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "# df[predictive_cols].tail(5)\n",
    "for row, result in zip(df[predictive_cols].tail(5).index  + pd.DateOffset(days=7), regr.predict(df[predictive_cols].tail(5))):\n",
    "    print(f\"Incidence on {row}: {get_unscaled_incidence(result)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
